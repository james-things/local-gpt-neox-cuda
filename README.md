# local-gpt-neox-cuda

 An simple example python script demonstrating a means of running GPT-NeoX-2.7B inference locally on a single GPU.
 
 Tested under Windows using Anaconda and transformers 4.24.0. Requires an installation of torch, with the appropriate cuda version as per the   system's installed cuda drivers.
