# local-gpt-neox-cuda

 An simple example python script demonstrating a means of running GPT-NeoX-2.7B inference locally on a single GPU.
 
 Tested under Windows using Anaconda. Requires transformers 4.12.0 and an installation of torch, with the appropriate cuda version as per the   installed cuda drivers.
